[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lukas Jung’s blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "neutral_elements_tidyselect.html",
    "href": "neutral_elements_tidyselect.html",
    "title": "Neutral elements in tidyselect",
    "section": "",
    "text": "Some operators used in the tidyselect framework have neutral elements. A neutral element is an expression that doesn’t make a difference when combined with other elements using the operator in question.\nUse cases are discussed below. First, a (hopefully) complete table of currently recommended operators and their neutral elements:"
  },
  {
    "objectID": "neutral_elements_tidyselect.html#use-cases",
    "href": "neutral_elements_tidyselect.html#use-cases",
    "title": "Neutral elements in tidyselect",
    "section": "Use cases",
    "text": "Use cases\nNeutral elements are not relevant for interactive data analysis. However, they can be used within functions that combine the tidyselect and tidy evaluation frameworks. The general workflow is as follows:\n\nCapture a user-supplied tidyselect specification with rlang::enexprs(...) or rlang::enexpr(specification_arg) and assign it to a new variable, selector1.\nCheck whether selector1 has a length of 1 or more — i.e., whether the user actually supplied anything. If not, capture a default expression using rlang::expr() and assign it to selector1.\nDepending on the value of another argument, assign one of multiple possible expressions to a new variable called selector2, using rlang::expr() or rlang::exprs(). One of these possible expressions should be a neutral element. Construct it as follows:\n\nIf selector2 is meant to be an additional selection constraint (i.e., one more test which the columns need to pass), it should be assigned rlang::expr(dplyr::everything()). Later, within across(), choose the & operator.\nElse, if selector2 is meant to (potentially) broaden the scope of selection rather than restricting it, selector2 should be assigned rlang::expr(where(isTRUE)). Later, within across(), choose the | operator.\n\nCall across() within mutate() or summarise(). Specify its .cols argument as c(!!!selector1) & !!selector2 or c(!!!selector1) | !!selector2, choosing the operator as explained in step 3. Note that you may need to change !! to !!! or vice versa:\n\nIf a selector* variable is a single expression, choose !! for it.\nElse, if it’s a list of expressions, choose !!! for it."
  },
  {
    "objectID": "neutral_elements_tidyselect.html#case-study-restore_zeros_df",
    "href": "neutral_elements_tidyselect.html#case-study-restore_zeros_df",
    "title": "Neutral elements in tidyselect",
    "section": "Case study: restore_zeros_df()",
    "text": "Case study: restore_zeros_df()\nHere is a simplified version of scrutiny::restore_zeros_df():\n\nrestore_zeros_df_simple <- function(.data, ..., .check_decimals = FALSE,\n                                    .width = NULL) {\n\n  # 1. Capture any tidyselect specifications by the user.\n  # If there aren't any...\n  selector1 <- rlang::enexprs(...)\n\n  # 2. ...`selector1` is now set up to select all numeric columns\n  # (this is a simplistic choice for succinctness):\n  if (length(selector1) == 0L) {\n    selector1 <- list(rlang::expr(where(is.numeric)))\n  }\n\n  # 3. If desired by the user, create an additional selection criterion:\n  # At least one value must have at least one decimal place. Otherwise...\n  if (.check_decimals) {\n    selector2 <- rlang::expr(\n      where(function(x) !all(scrutiny::decimal_places(x) == 0L))\n    )\n  } else {\n    # ... the new variable is set up to be evaluated as `everything()`,\n    # which is the neutral element of the `&` operator in tidyselect:\n    selector2 <- rlang::expr(dplyr::everything())\n  }\n\n  # 4. Columns are primarily selected via `selector1`, which defaults\n  # to selecting all numeric columns. Additional constrains might\n  # come via `selector2` (see above). The `.fns` argument uses an\n  # anonymous function to pass on the named arguments to a function\n  # that takes atomic vectors:\n  dplyr::mutate(.data, dplyr::across(\n    .cols = c(!!!selector1) & !!selector2,\n    .fns = function(data_dummy) {\n      scrutiny::restore_zeros(x = data_dummy, width = .width)\n    }\n  ))\n  \n}\n\nHere is a simplified version of scrutiny::split_by_parens(), which separates string columns that contain values like \"0.41 (0.28)\" and creates two new columns for every original one:\n\nsplit_simple <- function(.data, ..., .sep = \"parens\",\n                         .col1 = \"x\", .col2 = \"sd\") {\n\n  # Capture any valid tidyselect specification that might have been applied by\n  # the user to select columns from `.data`:\n  selector <- rlang::enexprs(...)\n\n  # In case no columns were specified that way, prepare and defuse a call that\n  # will select all columns:\n  if (length(selector) == 0L) {\n    selector <- rlang::exprs(dplyr::everything())\n  }\n  \n  # Prepare column name endings:\n  endings <- rep(c(.col1, .col2), times = ncol(.data))\n\n  # Apply the extractor functions `before_parens()` and `inside_parens()` to all\n  # selected columns from `.data` (see above), going by `.sep`, which is\n  # `\"parens\"` by default and will thus look for parentheses:\n  out <- dplyr::mutate(.data, dplyr::across(\n    .cols  = c(!!!selector),\n    .fns   = list(scrutiny::before_parens, scrutiny::inside_parens),\n    .names = \"{.col}_{endings}\",\n    sep = .sep\n  ))\n  \n  dplyr::select(out, -names(.data))\n}\n\nThe default works well if all columns are like this:\n\ndf1 <- tribble(\n    ~height,          ~mass,\n    \"0.09 (0.21)\",    \"0.19 (0.13)\",\n    \"0.19 (0.28)\",    \"0.53 (0.10)\"\n)\n\nsplit_simple(df1)\n\n# A tibble: 2 × 4\n  height_x height_sd mass_x mass_sd\n  <chr>    <chr>     <chr>  <chr>  \n1 0.09     0.21      0.19   0.13   \n2 0.19     0.28      0.53   0.10   \n\n\n\nSequences with :\nAs in base R, the : operator reduces a tidyselect expression to itself if it’s found on both sides:\n\niris |> \n    select(Sepal.Width:Sepal.Width)\n\n# A tibble: 3 × 1\n  Sepal.Width\n        <dbl>\n1         3.5\n2         3  \n3         3.2\n\niris |> \n    select(2:2)\n\n# A tibble: 3 × 1\n  Sepal.Width\n        <dbl>\n1         3.5\n2         3  \n3         3.2"
  },
  {
    "objectID": "tidyselect_neutral_elements.html",
    "href": "tidyselect_neutral_elements.html",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "",
    "text": "Some R functions like dplyr::select(), dplyr::across(), and tidyr::pivot_longer() use a special selection syntax. You may have seen starts_with() or everything() in a call to a function that selects columns:\nCode like this relies on a framework called tidyselect. Knowing the basics of tidyselect is beneficial for R users in general because select() and pivot_longer() are among the language’s most popular functions.\nHowever, the framework is especially interesting for package developers. Plugging your functions into tidyselect will give them more power and flexibility, and it will better align them with the tidyverse. This will make them easier accessible for users who are familiar with the high-profile functions mentioned above.\nThis blogpost is about programming with tidyselect. Although the framework allows you to implement your own low-level interfaces, I will only discuss wrappers around existing functions that use tidyselect. I will focus on dplyr::across(), an amazingly powerful tool that applies functions to multiple columns in a data frame. The role of tidyselect is to control which columns are operated on.\nThere is a nice dplyr vignette that introduces programming with across(). Be sure to check it out first to get a sense of the function’s capabilities. Here, I will discuss a style of working with tidyselect that I haven’t seen anywhere else. I hope the framework’s developers will either approve of my ideas or not read the post."
  },
  {
    "objectID": "tidyselect_neutral_elements.html#workflow",
    "href": "tidyselect_neutral_elements.html#workflow",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Workflow",
    "text": "Workflow\nFollow these steps to make practical use of guardrails in a tidyselect-wrapping function. Examples for each step are given in the next section.\n\nGive your function a cols argument with a selection like everything() or where(is.numeric) as its default.\nCheck for the condition that should be able to modify column selection. Think of a selection that fits your use case, defuse it with rlang::expr(), and set up the result to be assigned to a new variable, selection2, if the condition is met.\nChoose a tidyselect operator that fits your use case (see table above). Wrap its identity element into rlang::expr() and set up the result to be assigned to selection2 if the condition is not met.\nCall the tidyselect function of your choice. Within the call, inject the two selections like {{ cols }} OPERATOR !!selection2, using the operator chosen in step 3. If selection2 is a list rather than a single expression, inject it with !!! rather than !!.\n\nStep 2 suggests selection2 as a variable name because cols represents the first selection.\nIn step 4, make sure to write {{ cols }}, not !!cols. Since cols is a function argument that you didn’t defuse before step 4, !!cols would lead to an error:\n\nError in local_error_context(dots = dots, .index = i, mask = mask) : \n  promise already under evaluation: recursive default argument reference or earlier problems?\n\nConversely, for selection2, you should always use !! (or !!!), not {{ }}, because the embrace operator is only suitable for function arguments."
  },
  {
    "objectID": "tidyselect_neutral_elements.html#case-study-restore_zeros_df",
    "href": "tidyselect_neutral_elements.html#case-study-restore_zeros_df",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Case study: restore_zeros_df()",
    "text": "Case study: restore_zeros_df()\nAs an example for optional guardrails that restrict selection, here is a simplified version of scrutiny::restore_zeros_df(). The steps are numbered as in the workflow above.\nThis function converts numeric columns to string and pads their values with trailing zeros after the decimal point.\n\n# 1. This function has a `cols` argument with a\n# tidyselect expression as its default:\nrestore_simple <- function(data, cols = everything(),\n                           check_decimals = FALSE, width = NULL) {\n  \n  # 2. If desired by the user, create an additional selection criterion --\n  # at least one value per column must have at least one decimal place:\n  if (check_decimals) {\n    selection2 <- rlang::expr(\n      where(function(x) !all(scrutiny::decimal_places(x) == 0L))\n    )\n  } else {\n    # 3. Otherwise, the new variable is set up to be evaluated as \n    # `everything()`, which is an identity element of the `&`\n    # operator in tidyselect:\n    selection2 <- rlang::expr(everything())\n  }\n  \n  # 4. We call `across()` within `mutate()` because we want\n  # to modify multiple columns. These are primarily selected\n  # via `cols`, which defaults to selecting all numeric\n  # columns. The role of `selection2` is to further restrict\n  # the selection if desired by the user. Therefore, we\n  # combine both variables with `&`:\n  dplyr::mutate(data, dplyr::across(\n    .cols = {{ cols }} & !!selection2,\n    .fns  = function(data_dummy) {\n      scrutiny::restore_zeros(x = data_dummy, width = width)\n    }\n  ))\n  \n}\n\nLet’s try it out. First, we add an integer column to iris for testing the check_decimals argument. We also remove \"Species\" for simplicity: With a non-numeric column left, the function would actually need guardrails that are enabled by default as well, just like in multiply_df(). Else, the \"Species\" factor will be coerced to NAs again! Although multiple guardrails are not impossible, we circumvent the issue by choosing to work with numeric columns only.\n\niris_numeric <- iris |> \n  mutate(id = 1:3, Species = NULL)\n\nAll numeric columns are selected by default:\n\niris_numeric |> \n  restore_simple(width = 3)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width id   \n  <chr>        <chr>       <chr>        <chr>       <chr>\n1 5.100        3.500       1.400        0.200       1.000\n2 4.900        3.000       1.400        0.200       2.000\n3 4.700        3.200       1.300        0.200       3.000\n\n\nRegular user-supplied selections also work:\n\niris_numeric |> \n  restore_simple(cols = contains(\"i\"), width = 3)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width id   \n         <dbl> <chr>              <dbl> <chr>       <chr>\n1          5.1 3.500                1.4 0.200       1.000\n2          4.9 3.000                1.4 0.200       2.000\n3          4.7 3.200                1.3 0.200       3.000\n\n\nHere, id is excluded because setting check_decimals to TRUE leads to selection2 becoming the guardrail that ultimately returns FALSE for id:\n\niris_numeric |> \n  restore_simple(cols = contains(\"i\"), check_decimals = TRUE, width = 3)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width    id\n         <dbl> <chr>              <dbl> <chr>       <int>\n1          5.1 3.500                1.4 0.200           1\n2          4.9 3.000                1.4 0.200           2\n3          4.7 3.200                1.3 0.200           3\n\n\nNote that restore_simple() is not perfect. By default, for example, it doesn’t operate on numbers stored in string columns. scrutiny::restore_zeros_df() has a more judicious default that checks whether a column is numeric or otherwise coercible to numeric."
  },
  {
    "objectID": "tidyselect_neutral_elements.html#unclear-if-the-following-is-needed-maybe-just-elaborate-on-the-above-part",
    "href": "tidyselect_neutral_elements.html#unclear-if-the-following-is-needed-maybe-just-elaborate-on-the-above-part",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "UNCLEAR IF THE FOLLOWING IS NEEDED! MAYBE JUST ELABORATE ON THE ABOVE PART!",
    "text": "UNCLEAR IF THE FOLLOWING IS NEEDED! MAYBE JUST ELABORATE ON THE ABOVE PART!\n\nOLD WORKFLOW (PERHAPS OVERLY COMPLEX)\nIdentity elements are not directly relevant for interactive data analysis. However, they can be used to represent defaults for parts of a tidyselect specification. The general workflow is as follows:\n\nCapture a user-supplied tidyselect specification with rlang::enexprs(...) or rlang::enexpr(specification_arg) and assign it to a new variable, selector1.\nCheck whether selector1 has a length of 1 or more — i.e., whether the user actually supplied anything. If not, capture a default expression using list(rlang::expr(your_default)) and assign it to selector1.\nDepending on the value of another argument, assign one of multiple possible expressions to a new variable called selector2 using rlang::expr(). One of these possible expressions should be a identity element. The exact way to construct it depends on the alternative expression that it replaces:\n\nIf the alternative selector2 value is meant to be an additional selection constraint (i.e., one more test which the columns need to pass), selector2 in the default case should be assigned rlang::expr(dplyr::everything()). Later, within across(), choose the & operator.\nElse, if the alternative selector2 value is meant to (potentially) expand the scope of selection rather than restricting it, selector2 in the default case should be assigned rlang::expr(where(isTRUE)). Later, within across(), choose the | operator.\n\nCall across() within mutate() or summarise(). Specify its .cols argument as c(!!!selector1) & !!selector2 or c(!!!selector1) | !!selector2, choosing the operator as explained in step 3. Note that you may need to change !! to !!! or vice versa:\n\nIf a selector* variable is a single expression, choose !! for it.\nElse, if it’s a list of expressions, choose !!! for it.\n\n\nHere is a simplified version of scrutiny::split_by_parens(), which separates string columns that contain values like \"0.41 (0.28)\" and creates two new columns for every original one:\n\nsplit_simple <- function(data, ..., .sep = \"parens\",\n                         .col1 = \"x\", .col2 = \"sd\") {\n\n  # Capture any valid tidyselect specification that might have been applied by\n  # the user to select columns from `data`:\n  selector <- rlang::enexprs(...)\n\n  # In case no columns were specified that way, prepare and defuse a call that\n  # will select all columns:\n  if (length(selector) == 0L) {\n    selector <- rlang::exprs(dplyr::everything())\n  }\n  \n  # Prepare column name endings:\n  endings <- rep(c(.col1, .col2), times = ncol(data))\n\n  # Apply the extractor functions `before_parens()` and `inside_parens()` to all\n  # selected columns from `data` (see above), going by `.sep`, which is\n  # `\"parens\"` by default and will thus look for parentheses:\n  out <- dplyr::mutate(data, dplyr::across(\n    .cols  = c(!!!selector),\n    .fns   = list(scrutiny::before_parens, scrutiny::inside_parens),\n    .names = \"{.col}_{endings}\",\n    sep = .sep\n  ))\n  \n  dplyr::select(out, -names(data))\n}\n\nThe default works well if all columns look like this:\n\ndf1 <- tribble(\n    ~height,          ~mass,\n    \"0.09 (0.21)\",    \"0.19 (0.13)\",\n    \"0.19 (0.28)\",    \"0.53 (0.10)\"\n)\n\nsplit_simple(df1)\n\n# A tibble: 2 × 4\n  height_x height_sd mass_x mass_sd\n  <chr>    <chr>     <chr>  <chr>  \n1 0.09     0.21      0.19   0.13   \n2 0.19     0.28      0.53   0.10   \n\n\n\n\nSequences with :\nAs in base R, the : operator reduces a tidyselect expression to itself if it’s found on both sides:\n\niris |> \n    select(Sepal.Width:Sepal.Width)\n\n# A tibble: 3 × 1\n  Sepal.Width\n        <dbl>\n1         3.5\n2         3  \n3         3.2\n\niris |> \n    select(2:2)\n\n# A tibble: 3 × 1\n  Sepal.Width\n        <dbl>\n1         3.5\n2         3  \n3         3.2\n\n# Just like base R:\n2:2\n\n[1] 2"
  },
  {
    "objectID": "tidyselect_default_expressions.html",
    "href": "tidyselect_default_expressions.html",
    "title": "Programming with dplyr::across(), part I: Default expressions",
    "section": "",
    "text": "This is helpful in the following situation: You are writing a function that wraps a tidyselect-using function, like dplyr::across(), and passes a tidyselect specification on to it. By default, however, your new function should select a set of columns that is different from the set of columns that the wrapped function would select by default.\nYou don’t like the existing default, so you need to write a new one yourself.\nYou may already know that you can “tunnel” an argument into across() with {{ }}:\nThis works fine so far, but there is a catch. If the user doesn’t specify the selector argument, by_1000() won’t operate on any columns but simply return the tibble as is:\nPerhaps this is not the default you want. The function you apply, multiply by 1000, is an arithmetic operation. It might be best to select all numeric columns by default!\nHow to do this? You need to check whether or not the user actually specified the selector argument. If not, reassign a custom default expression to selector using rlang::expr(). It should only be evaluated within across(), where this requires the injection operator, !!, instead of {{ }}:"
  },
  {
    "objectID": "tidyselect_neutral_elements.html#identity-elements",
    "href": "tidyselect_neutral_elements.html#identity-elements",
    "title": "Programming with dplyr::across() and tidyselect",
    "section": "Identity elements",
    "text": "Identity elements\nAll tidyselect operators have identity elements. An identity element, or identity for short, is an expression that doesn’t make a difference when combined with other expressions using some specific operator. We saw above that where(is.numeric) & everything() had the same effect as where(is.numeric). Adding everything() with the & operator made no difference!\nIf this seems complicated, think of mathematics where identity can be very simple: \\(0\\) is the identity of addition, i.e., \\(x + 0 = x\\) for all real \\(x\\). Likewise, \\(1\\) is the identity of multiplication; \\(1x = x\\). You can see why these numbers are also called neutral elements: Throwing them into the equation with their respective operators doesn’t change the result.\nLet’s bring this closer to home. We can think of some identities in base R, each for one specific operation:\n\npaste0(\"abc\", \"\") returns \"abc\".\nc(5, NULL) returns 5. Likewise with all other atomic vectors.\nTRUE || TRUE, FALSE || TRUE, and even NA || TRUE return TRUE.\nUnsurprisingly, 0 + 5 and 1 * 5 both return 5.\n\nWhat might be more surprising is that the same principle can sometimes be useful when wrapping tidyselect functions, such as across(). The basic idea is that some condition may change which columns should be selected, and this change unfolds via an additional tidyselect expression. In such a context, an identity provides a safe fallback to which the additional expression will default if the condition is not met. This makes sure the selection is not changed when it’s not meant to be.\nWe can distinguish two basic use cases:\n\nDefault guardrails. The default protects the user from overly flexible selection (i.e., too broad or too narrow) by modifying the selection in a way that is characteristic of the specific use case of the wrapper function. If the user overrides the default, the guardrails are replaced by the identity. An example is the last version of multiply_df() above.\nExtra guardrails. In this case, there is usually no need to modify the selection. The identity is the default here! Sometimes, however, the user may choose to restrict or expand the selection in some way that has a special relation to the use case of the wrapper function. Overriding the Boolean default is a handy way of adding these guardrails, especially if manually modifying the selection would be difficult, bothersome, or both. An example is restore_simple(), discussed below.\n\nEach of these two can be subdivided into one use case that further restricts selection and one that further expands it. Emblematic for this are the & and | operators, but other operators can expand or restrict selection, as well.\n\n\n\n\n\n\n\n\n\nRestrict selection\nExpand selection\n\n\nDefault guardrails\nCertain columns should not normally be selected, even if the user-supplied tidyselect specification (or its default) would include them\nCertain columns should normally be selected, even if the user-supplied tidyselect specification (or its default) would exclude them\n\n\nExtra guardrails\nThe user chooses to apply some additional necessary conditions so that columns are selected more strictly\nThe user chooses to apply some additional sufficient conditions so that columns are selected more permissively\n\n\n\nHere is an overview of tidyselect’s unique set of identities:\n\n\n\n\n\n\n\n\nGuardrails use case\nTidyselect operator\nIdentity elements\n\n\n\n\nNA\n:\nElement on the other side (either location index or bare column name)\n\n\nRestrict selection by adding necessary conditions\n&\neverything(), !NULL; !where(is.null)); !where(isTRUE); !where(isFALSE)\n\n\nExpand selection by adding sufficient conditions\n|\n!everything(); NULL; where(is.null)); where(isTRUE); where(isFALSE)\n\n\nNA\n!\n!everything(); NULL; where(is.null)); where(isTRUE); where(isFALSE)\n\n\nNA\nc()\n!everything(); NULL; where(is.null)); where(isTRUE); where(isFALSE)\n\n\n\nNote that the guardrails override their identity element if and only if the condition in question is met. In the following, I will only discuss the first identity of each operator except :, i.e., everything() and !everything(). That’s because everything() is designated to be part of tidyselect’s API but the other identities aren’t."
  },
  {
    "objectID": "tidyselect_default_expressions.html#everything-below-is-probably-wrongheaded-because-it-insists-on-the-dots",
    "href": "tidyselect_default_expressions.html#everything-below-is-probably-wrongheaded-because-it-insists-on-the-dots",
    "title": "Programming with dplyr::across(), part I: Default expressions",
    "section": "EVERYTHING BELOW IS PROBABLY WRONGHEADED BECAUSE IT INSISTS ON THE DOTS",
    "text": "EVERYTHING BELOW IS PROBABLY WRONGHEADED BECAUSE IT INSISTS ON THE DOTS\nCalling c() works, but it’s not very elegant here. It may also confuse users who are familiar with dots-based tidyselect functions like dplyr::select(). The more natural solution would be to use the dots instead of a selector argument. Within across(), this requires the unquote-splice operator, !!!, instead of {{ }}:\n\nmultiply_df <- function(.data, ...) {\n  selector <- rlang::enexprs(...)\n  dplyr::mutate(.data, dplyr::across(\n    .cols = c(!!!selector),\n    .fns  = \\(x) x * 1000\n  ))\n}\n\niris |> \n  multiply_df(1, 3)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1         5100         3.5         1400         0.2 setosa \n2         4900         3           1400         0.2 setosa \n3         4700         3.2         1300         0.2 setosa \n\n\nThis works fine so far, but there is a catch. If the user doesn’t specify the dots, multiply_df() won’t operate on any columns but simply return the tibble as is:\n\niris |> \n  multiply_df()\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n\n# Same here:\niris |> \n  multiply_df()\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n\n\nPerhaps this is not the default you want. The function you apply, multiply by 1000, is an arithmetic operation. It might be best to select all numeric columns by default!\nHow to do this? You need to check whether or not the user actually supplied anything via the dots. That is, test whether the selector variable that captured the dots has a length greater than 0. Reassign a custom default expression to selector using list()1 and rlang::expr(). It should only be evaluated within across():\n\nmultiply_df <- function(.data, ...) {\n  selector <- rlang::enexprs(...)\n  if (length(selector) == 0L) {\n    selector <- list(rlang::expr(where(is.numeric)))\n  }\n  dplyr::mutate(.data, dplyr::across(\n    .cols = c(!!!selector),\n    .fns  = \\(x) x * 1000\n  ))\n}\n\niris |> \n  multiply_df()\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1         5100        3500         1400         200 setosa \n2         4900        3000         1400         200 setosa \n3         4700        3200         1300         200 setosa \n\n\n\n(This used to be a footnote:)\nrlang::expr() is wrapped in list() because we use the !!! construct in across(): Since rlang 0.4.0, it should only take lists of expressions, not single objects. We need !!!, not !!, because the user might enter multiple arguments in the dots. selector will then be a list of length > 0, and so won’t be replaced by the default expression."
  },
  {
    "objectID": "error_quarto_tidy_eval.html",
    "href": "error_quarto_tidy_eval.html",
    "title": "Error in Quarto with tidy evaluation",
    "section": "",
    "text": "library(dplyr) |> \n  suppressPackageStartupMessages()\n\niris <- iris |> \n  as_tibble() |> \n  slice(1:3)\n\nmult_1000 <- function(data, cols = everything(), check_numeric = TRUE) {\n  if (check_numeric) {\n    selection2 <- rlang::expr(where(is.numeric))\n  } else {\n    selection2 <- rlang::expr(everything())\n  }\n  dplyr::mutate(data, dplyr::across(\n    .cols = {{ cols }} & !!selection2,\n    .fns  = function(x) x * 1000\n  ))\n}\n\nmult_1000(iris)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1         5100        3500         1400         200 setosa \n2         4900        3000         1400         200 setosa \n3         4700        3200         1300         200 setosa"
  },
  {
    "objectID": "tidyselect_neutral_elements.html#identities-and-guardrails",
    "href": "tidyselect_neutral_elements.html#identities-and-guardrails",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Identities and guardrails",
    "text": "Identities and guardrails\nAll tidyselect operators have identity elements. An identity element, or identity for short, is an expression that doesn’t make a difference when combined with other expressions using some specific operator. We saw above that where(is.numeric) & everything() had the same effect as where(is.numeric). Adding everything() with the & operator didn’t have any impact!\nIf this seems complicated, think of mathematics where identity can be very simple: \\(0\\) is the identity of addition, i.e., \\(x + 0 = x\\) for all real \\(x\\). Likewise, \\(1\\) is the identity of multiplication; \\(1x = x\\). You can see why these numbers are also called neutral elements: Throwing them into the equation with their respective operators doesn’t change the result either way.\nLet’s bring this closer to home. We can think of some identities in base R, each for one specific operation:\n\npaste0(\"abc\", \"\") returns \"abc\".\nc(5, NULL) returns 5. Likewise with all other atomic vectors.\nUnsurprisingly, 0 + 5 and 1 * 5 both return 5.\n\nWhat might be more surprising is that the same principle can sometimes be useful when wrapping tidyselect functions, such as across(). The basic idea is that some condition may change which columns should be selected. This change to the user-supplied selection — or guardrail — unfolds through an additional tidyselect expression. In such a context, an identity provides a safe fallback to which the additional expression will default if the condition is not met. This makes sure the selection is not changed when it’s not meant to be.\nWe can distinguish two use cases:\n\nGuardrails enabled by default. The default protects the user from overly flexible selection (i.e., too broad or too narrow) by modifying the selection in a way that is characteristic of the specific use case of the wrapper function. If the user overrides the default, the guardrails are replaced by the identity. An example is the last version of multiply_df() above.\nGuardrails disabled by default. In this case, there is usually no need to modify the selection. The identity is the default here. Sometimes, however, the user may choose to restrict or expand the selection in some way that has a special relation to the use case of the wrapper function. Overriding the Boolean default is a handy way of adding these guardrails, especially if manually modifying the selection in the desired way would be difficult, bothersome, or both. An example is restore_simple(), discussed below.\n\nEach of these two can be subdivided into one use case that further restricts selection and one that further expands it. The & and | operators are emblematic for this, but other operators can expand or restrict selection, as well.\n\n\n\n\n\n\n\n\n\nRestrict selection\nExpand selection\n\n\nGuardrails enabled by default\nCertain columns should not normally be selected, even if the user-supplied tidyselect specification (or its default) would include them\nCertain columns should normally be selected, even if the user-supplied tidyselect specification (or its default) would exclude them\n\n\nGuardrails disabled by default\nThe user chooses to add necessary conditions so that columns are selected more strictly\nThe user chooses to add sufficient conditions so that columns are selected more permissively\n\n\n\nHere is an overview of tidyselect’s unique set of identities:\n\n\n\n\n\n\n\n\nGuardrails use case\nTidyselect operator\nIdentity elements\n\n\n\n\nNA\n:\nElement on the other side (either location index or bare column name)\n\n\nRestrict selection by adding necessary conditions\n&\neverything(), !NULL; !where(is.null)); !where(isTRUE); !where(isFALSE)\n\n\nExpand selection by adding sufficient conditions\n|\n!everything(); NULL; where(is.null)); where(isTRUE); where(isFALSE)\n\n\nNA\n!\n!everything(); NULL; where(is.null)); where(isTRUE); where(isFALSE)\n\n\nNA\nc()\n!everything(); NULL; where(is.null)); where(isTRUE); where(isFALSE)\n\n\n\nNote that the guardrails override their identity element if and only if the condition in question is met. In the following, I will only discuss the first identity of each operator except :, i.e., everything() and !everything(). That’s because everything() is designated to be part of tidyselect’s API but the other identities aren’t."
  },
  {
    "objectID": "tidyselect_neutral_elements.html#when-should-i-use-this",
    "href": "tidyselect_neutral_elements.html#when-should-i-use-this",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "When should I use this?",
    "text": "When should I use this?\nThe guardrails pattern has some downsides. First off, it compromises the tidyselect API. Even if the user’s selection says everything(), the function is no longer guaranteed to operate on all columns. Guardrails effectively split the selection between two or more parameters, and it’s up to the user to keep track of them.\nThis, in turn, puts an onus on the developer to handle questions of guardrails with care. Here are some recommendations in descending order of heavy-handedness:\n\nOnly enable guardrails by default if the default is essential to the purpose of your function. For example, arithmetic operations as in multiply_df() only make sense with numeric(-like) columns, so a default guardrail might be sensible.\nIf a selection is sensible but not essential — i.e., a matter of recommendation —, and it would be hard or tedious for the user to manually tweak the selection to the same effect, implement it as a guardrail that is disabled by default. An example is restore_simple().\nFinally, if the user can perform every sensible selection as straightforwardly as in where(is.numeric), don’t use any guardrails at all.\n\nGuardrails enabled by default should always be documented together with the cols argument, so that the user invariably stumbles upon them when learning about cols. This makes sure users are aware that selection is not controlled by cols alone. For example, here are the respective arguments from scrutiny::split_by_parens():\n\ncols\nSelect columns from data using tidyselect. Default is everything(), which selects all columns, but by default, they still need to pass check_sep.\ncheck_sep\nBoolean. If TRUE (the default), columns are skipped if they don’t contain the sep elements.\n\nIf guardrails are disabled by default, tweak the wording slightly. Here is a simplified rundown of the corresponding arguments in scrutiny::restore_zeros_df():\n\ncols\nSelect columns from data using tidyselect. Default is everything(), which selects all columns unless check_decimals is set to TRUE.\ncheck_decimals\nBoolean. If set to TRUE, the function will skip columns where no values have any decimal places. Default is FALSE.\n\nAll of this might create dependencies between arguments, thereby violating the tidyverse design guide. Guardrails do divide the selection into multiple arguments. However, the guide’s notion of “dependencies between arguments” seems to require that “only certain combinations [of argument specifications] are permitted” for the function to work. This is not the case with guardrails: At worst, they will change column selection in an unforeseen way.\nIt’s much more likely that they will prevent this very problem by tailoring selection to a function’s specific use case. They will exempt non-numeric values from arithmetic operations, or save strings from being split by substrings which they don’t contain. Guardrails make life easier for the user."
  },
  {
    "objectID": "tidyselect_old_workflow.html",
    "href": "tidyselect_old_workflow.html",
    "title": "tidyselect_old_workflow",
    "section": "",
    "text": "Identity elements are not directly relevant for interactive data analysis. However, they can be used to represent defaults for parts of a tidyselect specification. The general workflow is as follows:\n\nCapture a user-supplied tidyselect specification with rlang::enexprs(...) or rlang::enexpr(specification_arg) and assign it to a new variable, selector1.\nCheck whether selector1 has a length of 1 or more — i.e., whether the user actually supplied anything. If not, capture a default expression using list(rlang::expr(your_default)) and assign it to selector1.\nDepending on the value of another argument, assign one of multiple possible expressions to a new variable called selector2 using rlang::expr(). One of these possible expressions should be a identity element. The exact way to construct it depends on the alternative expression that it replaces:\n\nIf the alternative selector2 value is meant to be an additional selection constraint (i.e., one more test which the columns need to pass), selector2 in the default case should be assigned rlang::expr(dplyr::everything()). Later, within across(), choose the & operator.\nElse, if the alternative selector2 value is meant to (potentially) expand the scope of selection rather than restricting it, selector2 in the default case should be assigned rlang::expr(where(isTRUE)). Later, within across(), choose the | operator.\n\nCall across() within mutate() or summarise(). Specify its .cols argument as c(!!!selector1) & !!selector2 or c(!!!selector1) | !!selector2, choosing the operator as explained in step 3. Note that you may need to change !! to !!! or vice versa:\n\nIf a selector* variable is a single expression, choose !! for it.\nElse, if it’s a list of expressions, choose !!! for it.\n\n\nHere is a simplified version of scrutiny::split_by_parens(), which separates string columns that contain values like \"0.41 (0.28)\" and creates two new columns for every original one:\n\nsplit_simple <- function(data, ..., .sep = \"parens\",\n                         .col1 = \"x\", .col2 = \"sd\") {\n\n  # Capture any valid tidyselect specification that might have been applied by\n  # the user to select columns from `data`:\n  selector <- rlang::enexprs(...)\n\n  # In case no columns were specified that way, prepare and defuse a call that\n  # will select all columns:\n  if (length(selector) == 0L) {\n    selector <- rlang::exprs(dplyr::everything())\n  }\n  \n  # Prepare column name endings:\n  endings <- rep(c(.col1, .col2), times = ncol(data))\n\n  # Apply the extractor functions `before_parens()` and `inside_parens()` to all\n  # selected columns from `data` (see above), going by `.sep`, which is\n  # `\"parens\"` by default and will thus look for parentheses:\n  out <- dplyr::mutate(data, dplyr::across(\n    .cols  = c(!!!selector),\n    .fns   = list(scrutiny::before_parens, scrutiny::inside_parens),\n    .names = \"{.col}_{endings}\",\n    sep = .sep\n  ))\n  \n  dplyr::select(out, -names(data))\n}\n\nThe default works well if all columns look like this:\n\ndf1 <- tribble(\n    ~height,          ~mass,\n    \"0.09 (0.21)\",    \"0.19 (0.13)\",\n    \"0.19 (0.28)\",    \"0.53 (0.10)\"\n)\n\nsplit_simple(df1)\n\n\n\n\nAs in base R, the : operator reduces a tidyselect expression to itself if it’s found on both sides:\n\niris |> \n    select(Sepal.Width:Sepal.Width)\n\niris |> \n    select(2:2)\n\n# Just like base R:\n2:2"
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "Glossary of R terms",
    "section": "",
    "text": "Infix function (or infix operator). Syntactically special function with exactly two formal arguments that can be called by placing the function’s name in between the two arguments.\nData frame. List with these properties:\n\nAll elements have the same length.\nEach element is such that all of its own elements have the same type.\nIt inherits the S3 vector class data.frame.\n\nFunction factory. Function that returns a function.\nFunction operator. Function factory that takes one or more functions as arguments.\nAtomic vector. Vector with one of these types: integer, double, logical, character, complex, and raw.\nList. Non-atomic, non-expression vector.1\nBase R. Two senses of this term abound:2\n\nIn the narrow sense, base R is the base package.\nIn the broad sense, base R includes all packages of the R standard library, such as utils and stats.\n\n\n\n\n\n\n\nFootnotes\n\n\nLists are sometimes called “generic vectors”, notably in ?list. However, this term is rarely used outside of the official R documentation.↩︎\n\nThe distinction between the two senses of “base R” matters little in practice: the base package is always or almost always distributed along with the entire rest of the standard library. There are only two cases in which the distinction is important: 1. namespace conflicts, and 2. the development of a package that is meant to be submitted to CRAN or to another service that requires the namespaces of non-imported objects to be specified. The purpose of the requirements that lead to the second case is to prevent the first case. In either scenario, the solution is to specify the respective object’s namespace, usually in the form namespace::object.\n\n↩︎"
  },
  {
    "objectID": "tidyselect_neutral_elements.html#messages",
    "href": "tidyselect_neutral_elements.html#messages",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Messages",
    "text": "Messages\nGuardrails should never influence selection silently. I wrote a function that informs the user if one or more columns were excluded from selection by the guardrails. It’s used within the functions below but hidden here:\nTO DO: CALL THE BELOW FUNCTION IN THE CASE STUDY FUNCTIONS (FURTHER BELOW). THINK OF WHICH CONDITIONS SHOULD TRIGGER THIS. LOOK AT THE TWO scrutiny FUNCTIONS FOR INSPIRATION. THEN, DESCRIBE THIS PROCESS IN THE WORKFLOW SECTION. MAYBE ALSO WRITE AN inform_guardrails_expansion() FUNCTION; THEN APPLY IT ACCORDINGLY.\n\n\nShow code\n# Note: `names_cols_not_selected` and\n# `name_crucial_check` are required arguments.\n# `name_crucial_check` should be the name of\n# the `check_*` argument that excluded the columns\n# named in `names_cols_not_selected`.\n# All other arguments default to a generic message.\n# Customize them to make the message more specific.\n\ninform_guardrails_restriction <- function(names_cols_not_selected,\n                                          name_crucial_check,\n                                          msg_exclusion = paste(c(\"was\", \"were\"), \"not selected\"),\n                                          msg_reason = paste0(\"fulfill the criteria of `\", name_crucial_check, \"`\"),\n                                          msg_it_they = c(\"It doesn't\", \"They don't\")) {\n    if (length(names_cols_not_selected) == 1L) {\n        msg_col_cols <- \"1 column\"\n        msg_it_they <- msg_it_they[1L]\n        msg_exclusion <- msg_exclusion[1L]\n    }\n    else {\n        msg_col_cols <- paste(length(names_cols_not_selected), \"columns\")\n        msg_it_they <- msg_it_they[max(1L, length(msg_it_they))]\n        msg_exclusion <- msg_exclusion[max(1L, length(msg_exclusion))]\n    }\n    names_cols_not_selected <- paste0(\"`\", names_cols_not_selected, \"`\")\n    cli::cli_inform(c(\"i\" = \"{msg_col_cols} {msg_exclusion}: {names_cols_not_selected}.\", \n        \"i\" = \"{msg_it_they} {msg_reason}.\"))\n}"
  },
  {
    "objectID": "mode.html",
    "href": "mode.html",
    "title": "How to find the mode in R (or not)",
    "section": "",
    "text": "R is made for statistics. Surprisingly, though, there is no built-in R function to find the statistical mode: the most frequent value in a given distribution. (The base R function mode() has a very different use case.)\nHere are three functions to help you out.\nAll functions behave the same way if there is only one mode. If there are multiple modes, mode_first() only returns the one that appears first. mode_all() returns all modes. mode_single() returns NA in this case.\nAt their core, these functions are based on a Stack Overflow answer by Ken Williams. Go to Implementation notes below for details.\nWhat is so special about these functions? They really care about NAs. Let’s have a look."
  },
  {
    "objectID": "mode.html#outdated-disregard-everything-below",
    "href": "mode.html#outdated-disregard-everything-below",
    "title": "How to get the mode in R",
    "section": "Outdated; disregard everything below",
    "text": "Outdated; disregard everything below\nHere is one way to get the mode:\n\nmode_stat1 <- function(x) {\n    as(names(sort(table(x), decreasing = TRUE)[1]), typeof(x))\n}\n\nBut that’s hard to read. Let me explain it step by step:\n\nx |> \n  # Create a frequency table:\n  table() |> \n  # Order the values so that they start\n  # with the most frequent one:\n  sort(decreasing = TRUE) |> \n  # Pick the first value:\n  (\\(x) x[1])() |> \n  # Isolate the original value, stored\n  # here as the name of the count:\n  names() |> \n  # Make sure that the output has\n  # the same type as the input:\n  as(typeof(x))\n\nHere are some examples:\n\nx1 <- c(5, 9, 2, 6, 8, 1, 9, 3, 2, 2)\nx2 <- c(\"a\", \"b\", \"b\", \"c\", \"c\", \"c\")\n\nmode_stat1(x1)\n\n[1] 2\n\nmode_stat1(x2)\n\n[1] \"c\"\n\n\nAnother way:\n\nmode_stat2 <- function(x) {\n  out <- table(x)\n  out <- names(out)[out == max(out)]\n  # if (length(out > 1L)) {\n  #   warning(paste(\n  #     \"Mode should only be 1 value. It is\",\n  #     length(out), \"values.\"\n  #   ))\n  # }\n  as(out[1], typeof(x))\n}\n\nIf multiple values share the highest frequency, the function only returns the first one. To return all of them, remove the [1] index in the last line, so that it says as(out, typeof(x)).\n\n  if (length(out > 1L)) {\n    warning(paste(\n      \"Mode should only be 1 value. It is\",\n      length(out), \"values.\"\n    ))\n  }\n\nYet another way:\n\nmode_stat3 <- function(x) {\n  as(names(which.max(table(x))), typeof(x))\n}\n\nThis function is type-safe, so the output will always have the same type as the input. Some version of it has been around for a while, such as in this Stack Overflow post.\nThis one, from a Stack Overflow post, is much faster than the others (see performance measurement below):\n\nmode_stat4 <- function(x) {\n  ux <- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\nLet’s measure performance:\n\n# comparison <- bench::mark(\n#   mode_stat2 = mode_stat2(x),\n#   mode_stat3 = mode_stat3(x),\n#   mode_stat4 = mode_stat4(x),\n#   iterations = 50000\n# )\n\nThis seems wrong:\n\nmode_stat4 <- function(x) {\n  index_max <- NULL\n  count_max <- 0L\n  for (i in seq_along(x)) {\n    if (length(x[x == x[i]]) > count_max) {\n      count_max <- length(x[x == x[i]])\n    }\n  }\n  count_max\n}"
  },
  {
    "objectID": "tidyselect_neutral_elements.html#attempt-1-unspecific-selection",
    "href": "tidyselect_neutral_elements.html#attempt-1-unspecific-selection",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Attempt 1: unspecific selection",
    "text": "Attempt 1: unspecific selection\nLet’s start with a simple example. Here is a function that multiplies all numeric columns in a data frame by some number:\n\nmultiply_df <- function(data, cols = where(is.numeric), by = 1000) {\n  dplyr::mutate(data, dplyr::across(\n    .cols = {{ cols }},\n    .fns  = function(x) x * by\n  ))\n}\n\niris |> \n  multiply_df(1:2)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1         5100        3500          1.4         0.2 setosa \n2         4900        3000          1.4         0.2 setosa \n3         4700        3200          1.3         0.2 setosa \n\n\nBy default, all numeric columns are selected. That’s reasonable because our function should only operate on numbers. The selection is defused and injected into the across() call using {{ }}. It uses a cols argument instead of the dots. This is preferable in functions that have a main purpose other than selection itself — in this case, multiplying column values.\nAll works fine so far. But suppose the user makes a mistake. They take the complement (!) of all columns that end on \"Length\":\n\niris |> \n    multiply_df(!ends_with(\"Length\"))\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `dplyr::across(...)`.\nCaused by warning in `Ops.factor()`:\n! '*' not meaningful for factors\n\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <lgl>  \n1          5.1        3500          1.4         200 NA     \n2          4.9        3000          1.4         200 NA     \n3          4.7        3200          1.3         200 NA     \n\n\nWell, that’s unfortunate. \"Species\" is a factor column, not a numeric one,1 so its values are not supposed to be multiplied by any number. Indeed, it only ever makes sense for multiply_df() to operate on numeric columns.\nSpecifying the selection as !ends_with(\"Length\") & where(is.numeric) would solve the issue, but I think this puts too much of an onus on the user. Adding selection criteria beyond where(is.numeric) will be a typical use case of the cols argument. It would be burdensome to keep adding this boilerplate code on top of every meaningful selection. It would also be risky because not adding where(is.numeric) would lead to bugs like above.\nWhat’s more, the two elements of this selection are very different: There any many possible reasons to write selections like !ends_with(\"Length\"), all depending on the individual use case. By contrast, where(is.numeric) is much more fundamental to the whole purpose of multiply_df()."
  },
  {
    "objectID": "tidyselect_neutral_elements.html#attempt-2-hard-coded-specifications",
    "href": "tidyselect_neutral_elements.html#attempt-2-hard-coded-specifications",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Attempt 2: hard-coded specifications",
    "text": "Attempt 2: hard-coded specifications\nLet’s tweak the function a little. It should always test for where(is.numeric), so instead of setting this selection up as the default of cols, we hard-code it within the across() call. It’s now an additional test the columns need to pass in order to be selected — on top of any expressions the user might specify via cols to restrict selection even further.\nBy default, however, there are no restrictions beyond being numeric. That’s ensured by the new cols = everything() default. If the user doesn’t specify cols, the function will operate on all columns that are not screened out by where(is.numeric); i.e., all numeric columns. More on that below.\n\nmultiply_df <- function(data, cols = everything(), by = 1000) {\n  dplyr::mutate(data, dplyr::across(\n    .cols = {{ cols }} & where(is.numeric),\n    .fns  = function(x) x * by\n  ))\n}\n\niris |> \n    multiply_df(!ends_with(\"Length\"))\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          5.1        3500          1.4         200 setosa \n2          4.9        3000          1.4         200 setosa \n3          4.7        3200          1.3         200 setosa \n\niris |> \n    multiply_df()\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1         5100        3500         1400         200 setosa \n2         4900        3000         1400         200 setosa \n3         4700        3200         1300         200 setosa \n\n\nThis keeps the function from forcing multiplication upon non-numeric columns. Yet hard-coding a selection is not very elegant. It might make sense in a simple example such as this one, but more complex functions will require more nuanced decisions about column selection. I will explore such a case further below."
  },
  {
    "objectID": "tidyselect_neutral_elements.html#attempt-3-default-guardrails",
    "href": "tidyselect_neutral_elements.html#attempt-3-default-guardrails",
    "title": "Writing functions with dplyr::across() and tidyselect",
    "section": "Attempt 3: default guardrails",
    "text": "Attempt 3: default guardrails\nFrom now on, we will steer a middle course. Instead of either hard-coding selection or leaving it overly flexible, we add a Boolean argument with a default that ensures the function will only operate on numeric columns — unless the user overrides the default. (Again, it’s unclear when this would be useful with multiply_df(), but think of this simple case as a placeholder for more difficult ones.)\nThis latest version of the function has some features that might bewilder you. It’s worth taking a detour here and discuss them in detail. That’s what the next section does.\n\nmultiply_df <- function(data, cols = everything(), by = 1000,\n                        check_numeric = TRUE) {\n  if (check_numeric) {\n    selection2 <- rlang::expr(where(is.numeric))\n  } else {\n    selection2 <- rlang::expr(everything())\n  }\n  dplyr::mutate(data, dplyr::across(\n    .cols = {{ cols }} & !!selection2,\n    .fns  = function(x) x * by\n  ))\n}\n\nThe default works fine:\n\niris |> \n    multiply_df(!ends_with(\"Length\"))\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          5.1        3500          1.4         200 setosa \n2          4.9        3000          1.4         200 setosa \n3          4.7        3200          1.3         200 setosa \n\n\nOverriding the default leads to the same issue as before:\n\niris |> \n    multiply_df(!ends_with(\"Length\"), check_numeric = FALSE)\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `dplyr::across(...)`.\nCaused by warning in `Ops.factor()`:\n! '*' not meaningful for factors\n\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <lgl>  \n1          5.1        3500          1.4         200 NA     \n2          4.9        3000          1.4         200 NA     \n3          4.7        3200          1.3         200 NA"
  },
  {
    "objectID": "mode.html#get-a-single-mode-with-mode_stat",
    "href": "mode.html#get-a-single-mode-with-mode_stat",
    "title": "How to get the mode in R",
    "section": "Get a single mode with mode_stat()",
    "text": "Get a single mode with mode_stat()\nThink about what it means to look for the most frequent value in a distribution where some values are missing. Maybe there are so many missings that it’s impossible to tell which value is the most frequent one. For example:\n\nx1 <- c(1, 1, 2, 2, 2, 2, NA, NA, NA, NA)\nmode_stat(x1)\n\n[1] NA\n\n\nIf each NA stands in for 1, then 1 is the most frequent value. Accordingly for 2. The mode of x1 depends on the true values hiding behind NA. Since we don’t know these values, we don’t know the mode! The function should return NA, and it does.\nIgnore NAs using na.rm = TRUE if you must:\n\nmode_stat(x1, na.rm = TRUE)\n\n[1] 2\n\n\nThis distribution is different:\n\nx2 <- c(1, 1, 2, 2, 2, 2, NA)\nmode_stat(x2)\n\n[1] 2\n\n\nEven if the NA stands in for 1, there will only be three instances of 1 but four instances of 2. The mode is 2, independent of the true value behind NA."
  },
  {
    "objectID": "mode.html#get-all-modes-with-mode_stat_all",
    "href": "mode.html#get-all-modes-with-mode_stat_all",
    "title": "How to get the mode in R",
    "section": "Get all modes with mode_stat_all()",
    "text": "Get all modes with mode_stat_all()\nThis function allows for multiple modes:\n\nx3 <- c(1, 1, 2, 2, 3, 4, 5)\nmode_stat_all(x3)\n\n[1] 1 2\n\n\nIf some values are missing but there would be multiple modes when ignoring NAs, mode_stat_all() returns NA. That’s because missings can easily create an imbalance between the equally-frequent known values:\n\nx4 <- c(1, 1, 2, 2, NA)\nmode_stat_all(x4)\n\n[1] NA\n\n\nIf NA masks either 1 or 2, that number is the (single) mode. As before, if the mode depends on a missing value, the function returns NA.\nYet na.rm = TRUE makes the function ignore this:\n\nmode_stat_all(x4, na.rm = TRUE)\n\n[1] 1 2\n\n\nWhat about more specialized mode estimation in R? Search this CRAN Task View for “Mode estimation”. However, I haven’t checked how the packages listed there deal with missing values."
  },
  {
    "objectID": "mode.html#get-a-single-mode-with-mode_first",
    "href": "mode.html#get-a-single-mode-with-mode_first",
    "title": "How to find the mode in R (or not)",
    "section": "Get a single mode with mode_first()",
    "text": "Get a single mode with mode_first()\nEverything is fine here:\n\nx1 <- c(7, 8, 8, 9, 9, 9)\nmode_first(x1)\n\n[1] 9\n\n\nBut what if some values are missing? Think about what it means to look for the most frequent value in such a distribution. Maybe there are so many missings that it’s impossible to tell which value is the most frequent one. For example:\n\nx2 <- c(1, 1, 2, 2, 2, 2, NA, NA, NA, NA)\nmode_first(x2)\n\n[1] NA\n\n\nIf each NA stands in for 1, then 1 is the most frequent value. Accordingly for 2. The mode of x1 depends on the true values hiding behind NA. Since we don’t know these values, we don’t know the mode! The function should return NA, and it does.\nIgnore NAs using na.rm = TRUE if you must:\n\nmode_first(x2, na.rm = TRUE)\n\n[1] 2\n\n\nThis distribution is different:\n\nx3 <- c(7, 7, 8, 8, 8, 8, NA)\nmode_first(x3)\n\n[1] 8\n\n\nEven if the NA stands in for 7, there will only be three instances of 7 but four instances of 8. The mode is 8, independent of the true value behind NA."
  },
  {
    "objectID": "mode.html#get-all-modes-with-mode_all",
    "href": "mode.html#get-all-modes-with-mode_all",
    "title": "How to find the mode in R (or not)",
    "section": "Get all modes with mode_all()",
    "text": "Get all modes with mode_all()\nThis function captures multiple modes:\n\nx4 <- c(\"a\", \"a\", \"b\", \"b\", \"c\", \"d\", \"e\")\nmode_all(x4)\n\n[1] \"a\" \"b\"\n\n\nIf some values are missing but there would be multiple modes when ignoring NAs, mode_all() returns NA. That’s because missings can easily create an imbalance between the equally-frequent known values:\n\nx5 <- c(1, 1, 2, 2, NA)\nmode_all(x5)\n\n[1] NA\n\n\nIf NA masks either 1 or 2, that number is the (single) mode. As before, if the mode depends on missing values, the function returns NA.\nYet na.rm = TRUE makes the function ignore this:\n\nmode_all(x5, na.rm = TRUE)\n\n[1] 1 2"
  },
  {
    "objectID": "mode.html#get-the-n-th-mode-with-mode_nth",
    "href": "mode.html#get-the-n-th-mode-with-mode_nth",
    "title": "How to find the mode in R",
    "section": "Get the n-th mode with mode_nth()",
    "text": "Get the n-th mode with mode_nth()\nWhat if we want a specific mode other than the first?\n\nx5 <- c(1, 1, 2, 3, 3, 4)\nmode_nth(x5, n = 2)\n\n[1] 3\n\n\nHere, 1 and 3 are the modes. mode_nth() with n = 2 finds the second mode, i.e., 3.\nIf n is greater than the number of modes, mode_nth() will raise an error:\n\nmode_nth(x5, n = 4)\n\nError in mode_nth(x5, n = 4): `n` is 4 but there are only 2 modes.\n\n\nWhat about more specialized mode estimation in R? Search this CRAN Task View for “Mode estimation”. However, I haven’t checked how the packages listed there deal with missing values."
  },
  {
    "objectID": "mode.html#learn-more",
    "href": "mode.html#learn-more",
    "title": "How to find the mode in R (or not)",
    "section": "Learn more",
    "text": "Learn more\nWhat about other mode estimation techniques in R? Search this CRAN Task View for “Mode estimation”. However, I haven’t checked how the packages listed there deal with missing values."
  },
  {
    "objectID": "mode.html#implementation-notes",
    "href": "mode.html#implementation-notes",
    "title": "How to find the mode in R (or not)",
    "section": "Implementation notes",
    "text": "Implementation notes\nThe first two functions are adapted with modifications from this Stack Overflow answer. They only behave differently from the original ones when handling missing values. I changed their names to better distinguish them from base::mode() and from each other. Note that mode_single() internally calls mode_all(), and mode_all() calls mode_first().\nThe na.rm argument follows similar R functions, such as mean() and median(). Still, it shouldn’t be set to TRUE without a strong rationale. Missing values have real meaning, and all these functions handle them accordingly — like base R operators do.\nClick “Show code” to see step-by-step commented versions of all three functions.\n\n\nShow code\nmode_first <- function(x, na.rm = FALSE) {\n  # We first determine the unique known values\n  # of `x`. `NA`s are ignored at this point\n  # because they will receive special treatment\n  # later on.\n  ux <- unique(x[!is.na(x)])\n  # Find the index of the most frequent known\n  # value (the possible mode) and subset this\n  # value:\n  mode1 <- ux[which.max(tabulate(match(x, ux)))]\n  # The present implementation only differs from the\n  # linked original function in terms of `NA` handling.\n  # Therefore, it returns `mode1` just like that function\n  # does if missing values are not an issue -- either\n  # because the user chose to ignore them (`na.rm = TRUE`)\n  # or because there are no `NA`s to begin with:\n  if (na.rm || !any(is.na(x))) {\n    mode1\n  } else {\n  # At this point, we know that one or more\n  # values are missing. We call a helper function,\n  # documented further below, that adjudicates\n  # whether or not it's still possible to determine\n  # the mode. If so, it returns the mode; if not,\n  # it returns `NA`:\n    adjudicate_mode_na(x, ux, mode1, TRUE)\n  }\n}\n\nmode_all <- function(x, na.rm = FALSE) {\n  # As above, we first determine the unique\n  # known values of `x`. `NA`s are ignored\n  # at this point because they will receive\n  # special treatment later on.\n  ux <- unique(x[!is.na(x)])\n  # Count the instances of each known value:\n  tab <- tabulate(match(x, ux))\n  # Subset the vector of unique known values\n  # at the indices corresponding to the\n  # most frequent known values:\n  modes <- ux[tab == max(tab)]\n  # A seemingly unimodal distribution is\n  # subject to the `NA`-related caveats\n  # described in `mode_first()`, so we call\n  # the same `NA` helper as that function:\n  if (length(modes) == 1L) {\n    adjudicate_mode_na(x, ux, modes, TRUE)\n    # Multimodal distributions without `NA`s\n    # have a clearly determined set of modes.\n    # If they do have `NA`s, the user can\n    # (but probably shouldn't) ignore the\n    # issue by setting `na.rm` to `TRUE`:\n  } else if (na.rm || !any(is.na(x))) {\n    modes\n    # Any missing value could mask any of the\n    # known values tied for most frequent --\n    # and break the tie. This makes it\n    # impossible to determine the true set\n    # of modes, so the function returns `NA`:\n  } else {\n    methods::as(NA, typeof(x))\n  }\n}\n\nmode_single <- function(x, na.rm = FALSE) {\n  # Unlike the functions above, this\n  # one requires manual `NA` removal:\n  if (na.rm) {\n    x <- x[!is.na(x)]\n  }\n  # We also need to check the number of\n  # modes here, so we call `mode_all()`:\n  mode1 <- mode_all(x, na.rm)\n  # As the name says, if the distribution\n  # has a single mode (that passes the\n  # `NA` test), that value is returned.\n  # `NA` testing without allowing for ties\n  # between the `mode1` count and the sum\n  # of the `mode2` and `NA` counts\n  # (`FALSE` at the end) is necessary here\n  # because we need to make sure that\n  # `mode1` is really the only mode, even\n  # if all `NA`s stand in for `mode2`:\n  if (length(mode1) == 1L) {\n    adjudicate_mode_na(x, unique(x[!is.na(x)]), mode1, FALSE)\n  # Multimodal distributions are always `NA`.\n  # Some users prefer this stricter way of\n  # estimating the mode, or they require it\n  # for their specific use cases.\n  } else {\n    methods::as(NA, typeof(x))\n  }\n}\n\nadjudicate_mode_na <- function(x, ux, mode1, allow_tie) {\n  # Some values might be missing. We need to check\n  # whether there are so many missings that the most\n  # frequent known value, `mode1`, might be less\n  # frequent than the second-most frequent one (or\n  # the first value tied with `mode1` but appearing\n  # after it) if all the `NA`s mask the latter.\n  # To do so, we need to find this second value.\n  # We look for a possible mode much like above,\n  # but this time, we exclude the `mode1` values:\n  mode2 <- ux[which.max(tabulate(match(x[x != mode1], ux)))]\n  # Count instances of the three relevant available\n  # values -- most and second-most frequent known\n  # values plus missing values:\n  count_mode1 <- length(x[x == mode1])\n  count_mode2_na <- length(x[x == mode2]) + length(x[is.na(x)])\n  # Two of the functions above only require `mode1`\n  # to be at least as frequent as the sum of the\n  # other two counts (see below). However,\n  # `mode_single()` is more strict because\n  # it is meant to rule out that the true count\n  # of `mode2` is just as high as that of `mode1`.\n  # If this is even possible, `mode_single()`\n  # needs to return `NA` because it only\n  # allows for a single mode.\n  if (allow_tie) {\n    mode1_frequent_enough <- count_mode1 >= count_mode2_na\n  } else {\n    mode1_frequent_enough <- count_mode1 > count_mode2_na\n  }\n  # (Assuming `allow_tie = TRUE`:)\n  # `mode1` is the true mode only if it's\n  # at least as frequent as the sum of the\n  # other two counts. Otherwise, if all the\n  # `NA`s mask `mode2` values, the true count\n  # of `mode2` would be higher than that of\n  # `mode1`. We don't know which values hide\n  # behind `NA`, so we can't rule out this\n  # second scenario if the known count of\n  # `mode1` is lower than a possibly true\n  # count of `mode2`. Therefore, if\n  # `count_mode1` is not large enough, the\n  # function returns `NA` (coerced to the\n  # same type as the input, `x`):\n  if (mode1_frequent_enough) {\n    mode1\n  } else {\n    methods::as(NA, typeof(x))\n  }\n}"
  },
  {
    "objectID": "mode.html#get-the-first-mode-with-mode_first",
    "href": "mode.html#get-the-first-mode-with-mode_first",
    "title": "How to find the mode in R (or not)",
    "section": "Get the first mode with mode_first()",
    "text": "Get the first mode with mode_first()\nEverything is fine here:\n\nx1 <- c(7, 8, 8, 9, 9, 9)\nmode_first(x1)\n\n[1] 9\n\n\nBut what if some values are missing? Think about what it means to look for the most frequent value in such a distribution. Maybe there are so many missings that it’s impossible to tell which value is the most frequent one. For example:\n\nx2 <- c(1, 1, 2, 2, 2, 2, NA, NA, NA, NA)\nmode_first(x2)\n\n[1] NA\n\n\nIf each NA stands in for 1, then 1 is the most frequent value. Accordingly for 2. The mode of x1 depends on the true values hiding behind NA. Since we don’t know these values, we don’t know the mode! The function should return NA, and it does.\nIgnore NAs using na.rm = TRUE if you must:\n\nmode_first(x2, na.rm = TRUE)\n\n[1] 2\n\n\nThis distribution is different:\n\nx3 <- c(7, 7, 8, 8, 8, 8, NA)\nmode_first(x3)\n\n[1] 8\n\n\nEven if the NA stands in for 7, there will only be three instances of 7 but four instances of 8. The mode is 8, independent of the true value behind NA."
  },
  {
    "objectID": "mode.html#get-the-single-mode-or-na-with-mode_single",
    "href": "mode.html#get-the-single-mode-or-na-with-mode_single",
    "title": "How to find the mode in R (or not)",
    "section": "Get the single mode (or NA) with mode_single()",
    "text": "Get the single mode (or NA) with mode_single()\nmode_single() is stricter than mode_first(): It returns NA if there are — or might be — multiple modes. Otherwise, it works the same way.\n\nx6 <- c(3, 4, 4, 5, 5, 5)\nmode_single(x6)\n\n[1] 5\n\nx7 <- c(\"x\", \"x\", \"y\", \"y\", \"z\")\nmode_single(x7)\n\n[1] NA\n\nx8 <- c(1, 1, 2, NA)\nmode_single(x8)\n\n[1] NA"
  }
]